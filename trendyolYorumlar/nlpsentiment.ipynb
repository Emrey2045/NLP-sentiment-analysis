{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1UHkgk2i1bMS94tn-NyXYv7ghgtlAKiCQ","authorship_tag":"ABX9TyMf2OUTk6zGmXbExL9pigr1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VPm9Nqu7SbkJ","outputId":"832aaee6-37db-4b0f-97af-141ae46a9102"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.3\n","Collecting googletrans\n","  Downloading googletrans-4.0.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.16.0)\n","Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (4.2.0)\n","Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n","Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n","Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.13.2)\n","Downloading googletrans-4.0.2-py3-none-any.whl (18 kB)\n","Installing collected packages: googletrans\n","Successfully installed googletrans-4.0.2\n"]}],"source":["# -*- coding: utf-8 -*-\n","!pip install evaluate\n","!pip install googletrans\n","\n","\n","import torch.nn.functional as F\n","import pandas as pd\n","import torch\n","import evaluate\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    Trainer,\n","    TrainingArguments,\n","    EarlyStoppingCallback,\n",")\n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from googletrans import Translator\n","from google.colab import drive\n","\n"]},{"cell_type":"code","source":["#  GOOGLE DRIVE'ı BAĞLAMA\n","drive.mount('/content/drive')\n","\n","# CSV DOSYANIN YOLUNU BELİRLE (Drive'daki konumuna göre düzenle!)\n","csv_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/Duyguanalizveriseti2.csv\"\n","\n","#  CSV dosyasını oku ve sütun isimlerini düzenle\n","df = pd.read_csv(csv_path)\n","df.columns = [\"yorum\", \"etiket\"]\n","\n","print(\"\\n Veri kümesi (İlk 5 satır):\")\n","print(df.head())\n","\n","\n","\n","\n","\n"],"metadata":{"id":"RHucwrJFSyAa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  VERİ ARTIRMA (DATA AUGMENTATION) - İSTEĞE BAĞLI\n","ENABLE_DATA_AUGMENTATION = False  # Hızlı eğitim için False kullanabilirsiniz.\n","\n","def augment_dataset(df, num_augments=3):\n","    translator = Translator()\n","    augmented_texts = []\n","    augmented_labels = []\n","\n","    for text, label in zip(df['yorum'], df['etiket']):\n","        augmented_texts.append(text)\n","        augmented_labels.append(label)\n","\n","        for _ in range(num_augments):\n","            try:\n","                translated = translator.translate(text, src='tr', dest='en').text\n","                back_translated = translator.translate(translated, src='en', dest='tr').text\n","                if back_translated != text:\n","                    augmented_texts.append(back_translated)\n","                    augmented_labels.append(label)\n","            except Exception:\n","                continue\n","\n","    return pd.DataFrame({'yorum': augmented_texts, 'etiket': augmented_labels})\n","\n","if ENABLE_DATA_AUGMENTATION:\n","    print(\"\\n Veri artırma işlemi başladı... (Bu işlem uzun sürebilir)\")\n","    df = augment_dataset(df)\n"],"metadata":{"id":"-rn8xpiLSzb8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# VERİYİ EĞİTİM VE DOĞRULAMA KÜMELERİNE AYIRMA\n","train_texts, val_texts, train_labels, val_labels = train_test_split(\n","    df[\"yorum\"],\n","    df[\"etiket\"],\n","    test_size=0.2,\n","    stratify=df[\"etiket\"],\n","    random_state=42\n",")"],"metadata":{"id":"1ANvpijgS2kU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  MODEL VE TOKENIZER TANIMLAMA\n","model_name = \"dbmdz/bert-base-turkish-cased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    num_labels=2,\n","    id2label={0: \"MUTSUZ\", 1: \"MUTLU\" },\n","    label2id={\"MUTSUZ\": 0, \"MUTLU\": 1}\n",")"],"metadata":{"id":"t0gvDgY2S5G_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  GPU AYARI (Eğer varsa GPU kullan)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"],"metadata":{"id":"ozuE7JGsS60c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# VERİLERİ TOKENİZE ETME\n","train_encodings = tokenizer(\n","    train_texts.tolist(),\n","    truncation=True,\n","    padding=True,\n","    max_length=128,\n",")\n","\n","val_encodings = tokenizer(\n","    val_texts.tolist(),\n","    truncation=True,\n","    padding=True,\n","    max_length=128,\n",")"],"metadata":{"id":"jlTJRwzqS7-r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  DATASET SINIFI TANIMLAMA\n","class SentimentDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        return {\n","            \"input_ids\": torch.tensor(self.encodings[\"input_ids\"][idx]),\n","            \"attention_mask\": torch.tensor(self.encodings[\"attention_mask\"][idx]),\n","            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n","        }\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = SentimentDataset(train_encodings, train_labels.tolist())\n","val_dataset = SentimentDataset(val_encodings, val_labels.tolist())\n"],"metadata":{"id":"fpLNmBUTS72v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  EĞİTİM AYARLARI\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    learning_rate=3e-5,\n","    weight_decay=0.1,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n","    logging_dir=\"./logs\",\n","    report_to=\"none\",\n","    seed=42,\n","    fp16=torch.cuda.is_available(),  # GPU varsa FP16 kullanılır\n","    gradient_accumulation_steps=2\n",")\n"],"metadata":{"id":"KaBNldBcS--Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics = evaluate.combine([\"accuracy\", \"precision\", \"recall\", \"f1\"])\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metrics.compute(predictions=predictions, references=labels)\n"],"metadata":{"id":"KOPpcfVpS-3z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TRAINER OLUŞTURMA\n","from transformers import Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",")\n"],"metadata":{"id":"swoKFOCiS-xk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  MODELİ EĞİTME\n","print(\"\\nEğitim başlıyor...\")\n","trainer.train()"],"metadata":{"id":"8goXkH9oS-qj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  MODELİ KAYDETME\n","# Modeli eğittikten sonra kaydetme\n","model_save_path = \"/content/drive/My Drive/saved_model\"\n","trainer.save_model(model_save_path)\n","\n","# Tokenizer'ü de kaydediyoruz\n","tokenizer.save_pretrained(model_save_path)\n","print(f\"\\nModel ve tokenizer kaydedildi: {model_save_path}\")\n","\n","# Daha sonra tahmin yapmak için kaydedilen model ve tokenizer'ü yükleyin:\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_save_path)\n","model = AutoModelForSequenceClassification.from_pretrained(model_save_path)\n","model.to(device)\n","\n","\n","# Test için kullanılacak cümleler\n","test_cases = [\n","    \"Ürün kalitesi mükemmel.\",\n","    \"Hizmet harikaydı kesinlikle tekrar gelirim\",\n","    \"Bu kadar kötü bir deneyim beklemiyordum\",\n","    \"Yeni gelen güncellemeden sonra uygulama düzgün çalışmamaya başladı.\",\n","    \"Ürün bok gibiydi.\",\n","    \"10/10 ürün çok güzel\",\n","    \"Harika cok beyendim.\",\n","    \"Ürün bozuk geldi iade edeceğim.\",\n","    \"Bir daha alıcammm\",\n","    \"işimi gördü.\",\n","    \"Yunus önermişti aldım memnunum.\"\n","]\n","\n","print(\"\\nTest Sonuçları:\")\n","for text in test_cases:\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    probs = F.softmax(outputs.logits, dim=-1)\n","    confidence, predicted_class = torch.max(probs, dim=-1)\n","    label = \"MUTLU\" if predicted_class.item() == 1 else \"MUTSUZ\"\n","    print(f\"\\nMetin: {text}\")\n","    print(f\"Tahmin: {label} (%{confidence.item() * 100:.1f})\")"],"metadata":{"id":"6h6bbJHWS-kE"},"execution_count":null,"outputs":[]}]}